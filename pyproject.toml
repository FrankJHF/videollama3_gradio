[project]
name = "videollama3-gui"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "accelerate==1.0.1",
    "decord>=0.6.0",
    "ffmpeg-python>=0.2.0",
    "flash-attn",
    "gradio==5.0.1",
    "imageio==2.34.0",
    "opencv-python==4.6.0.66",
    "pydantic==2.10.6",
    "spaces>=0.37.1",
    "timm>=1.0.17",
    "torch==2.4.0",
    "torchvision==0.19.0",
    "transformers==4.46.3",
]

[tool.uv.sources]
flash-attn = { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl" }
torch = { index = "pytorch-cu121"}
torchvision = { index = "pytorch-cu121"}

[[tool.uv.index]]
name = "pytorch-cu121"
url = "https://download.pytorch.org/whl/cu121"
explicit = true
