## ç³»ç»Ÿè¦æ±‚

- **Python**: >= 3.10
- **CUDA**: >= 12.1 (æ”¯æŒ GPU åŠ é€Ÿ)
- **å†…å­˜**: >= 16GB RAM
- **æ˜¾å­˜**: >= 8GB VRAM (æ¨è 16GB+)

## å¿«é€Ÿå®‰è£…

### 1. å…‹éš†é¡¹ç›®

```bash
git clone <repository-url>
cd videollama3_gui
```

### 2. ä½¿ç”¨ uv å®‰è£…ä¾èµ– (æ¨è)

```bash
# å®‰è£… uv (å¦‚æœå°šæœªå®‰è£…)
curl -LsSf https://astral.sh/uv/install.sh | sh

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
uv sync

# æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate     # Windows
```

### 3. ä¼ ç»Ÿå®‰è£…æ–¹å¼

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements-infer.txt
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
videollama3_gui/
â”œâ”€â”€ app.py                    # ä¸»åº”ç”¨ç¨‹åº
â”œâ”€â”€ infer.py                  # æ¨ç†è„šæœ¬
â”œâ”€â”€ fix_weights.py            # æƒé‡ä¿®å¤å·¥å…·
â”œâ”€â”€ config.yaml               # é…ç½®æ–‡ä»¶
â”œâ”€â”€ pyproject.toml            # uv é¡¹ç›®é…ç½®
â”œâ”€â”€ examples/                 # ç¤ºä¾‹è§†é¢‘
â”‚   â”œâ”€â”€ è£…è¿è¿‡ç¨‹ç«ç¾.mp4
â”‚   â”œâ”€â”€ è®¾å¤‡æ¼æ²¹ç€ç«.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ VideoLLaMA3/              # æ ¸å¿ƒæ¡†æ¶
â”œâ”€â”€ model_ck/                 # ä¸»æ¨¡å‹ç›®å½•
â”œâ”€â”€ model_c2h/                # å¤‡ç”¨æ¨¡å‹ç›®å½•
â””â”€â”€ assets/                   # é™æ€èµ„æº
```

## ğŸ® ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨ Web ç•Œé¢

```bash
python app.py
```

è®¿é—® `http://localhost:7860` å³å¯ä½¿ç”¨ Web ç•Œé¢ã€‚

### å‘½ä»¤è¡Œæ¨ç†

```bash
python infer.py
```

### é…ç½®ä¿®æ”¹

ç¼–è¾‘ `config.yaml` æ–‡ä»¶è°ƒæ•´æ¨¡å‹å’Œæ¨ç†å‚æ•°ï¼š

```yaml
model:
  path: model_ck              # æ¨¡å‹è·¯å¾„
  device: cuda                # è®¡ç®—è®¾å¤‡
  torch_dtype: bfloat16       # æ•°æ®ç±»å‹
  attn_implementation: flash_attention_2

inference:
  fps: 2                      # è§†é¢‘é‡‡æ ·å¸§ç‡
  max_frames: 160             # æœ€å¤§å¤„ç†å¸§æ•°
  max_new_tokens: 180         # æœ€å¤§ç”Ÿæˆtokenæ•°
  timeout: 300                # æ¨ç†è¶…æ—¶æ—¶é—´(ç§’)
```
